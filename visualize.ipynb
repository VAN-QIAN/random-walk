{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "import lightning as L\n",
    "import torch_geometric.data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import graph_walker  # pylint: disable=import-error\n",
    "\n",
    "from src.data import DatasetBuilder\n",
    "from src.data import GraphSeparationCSLDataset, GraphSeparationCSLWalker\n",
    "from src.data import GraphSeparationSR16Dataset, GraphSeparationSR16Walker\n",
    "from src.data import GraphSeparationSR25Dataset, GraphSeparationSR25Walker\n",
    "from src.model import Model\n",
    "from src.train.lit_module import LitModule\n",
    "\n",
    "dataset_name = 'SR25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = edict()\n",
    "if dataset_name == 'SR16':\n",
    "    args.config = 'configs/graph_separation/sr16_deberta.yaml'\n",
    "elif dataset_name == 'SR25':\n",
    "    args.config = 'configs/graph_separation/sr25_deberta.yaml'\n",
    "elif dataset_name == 'CSL':\n",
    "    args.config = 'configs/graph_separation/csl_deberta.yaml'\n",
    "with open(args.config, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    config = edict(config)\n",
    "config.test_mode = True\n",
    "config.test_n_walks = 1\n",
    "config.compile = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(config.seed, workers=True)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "if dataset_name == 'SR16':\n",
    "    walker = GraphSeparationSR16Walker(config)\n",
    "    ds_builder = DatasetBuilder('graph_separation_sr16', True, GraphSeparationSR16Dataset, 'experiments/data', config)\n",
    "elif dataset_name == 'SR25':\n",
    "    walker = GraphSeparationSR25Walker(config)\n",
    "    ds_builder = DatasetBuilder('graph_separation_sr25', True, GraphSeparationSR25Dataset, 'experiments/data', config)\n",
    "elif dataset_name == 'CSL':\n",
    "    walker = GraphSeparationCSLWalker(config)\n",
    "    ds_builder = DatasetBuilder('graph_separation_csl', True, GraphSeparationCSLDataset, 'experiments/data', config)\n",
    "walker.register_ds_builder(ds_builder)\n",
    "print(walker)\n",
    "\n",
    "dataset = ds_builder.train_dataset()\n",
    "dataset.cuda()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    walker=walker,\n",
    "    backbone='microsoft/deberta-base',\n",
    "    dropout=None,\n",
    "    att_dropout=None,\n",
    "    head_dropout=0.0,\n",
    "    vocab_size=-1,\n",
    "    max_length=512,\n",
    "    pretrained=True,\n",
    "    pretrained_tokenizer=True,\n",
    "    is_compiled=False,\n",
    "    deberta_use_pooler=False,\n",
    "    debug_mode=False\n",
    ")\n",
    "model = LitModule(\n",
    "    model=model,\n",
    "    optimizer_config=None,\n",
    "    lr_scheduler_config=None\n",
    ")\n",
    "if dataset_name == 'SR16':\n",
    "    ckpt_path = 'experiments/checkpoints/graph_separation_sr16/microsoft_deberta-base,pt_True,l_512,w_min_degree,wl_1000,n_True,nw_1,enw_1,b_256,es_validation_loss_min_100,lr_2e-05_2e-05,steps_100000,wu_5000,wd_0.01,clip_2,seed_42,/best.ckpt'\n",
    "elif dataset_name == 'SR25':\n",
    "    ckpt_path = 'experiments/checkpoints/graph_separation_sr25/microsoft_deberta-base,pt_True,l_512,w_min_degree,wl_1000,n_True,nw_1,enw_1,b_256x8,es_validation_loss_min_100,lr_2e-05_2e-05,steps_100000,wu_5000,wd_0.01,seed_42,/best.ckpt'\n",
    "elif dataset_name == 'CSL':\n",
    "    ckpt_path = 'experiments/checkpoints/graph_separation_csl/microsoft_deberta-base,pt_True,l_512,w_min_degree,wl_1000,n_True,nw_2,enw_8,b_128,es_validation_loss_min_100,lr_2e-05_2e-05,steps_100000,wu_5000,wd_0.01,clip_2,seed_42,/best.ckpt'\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(root, data_idx, layer_idx, head_idx, seed, draw_graph=False):\n",
    "    num_layers = 12\n",
    "    num_heads = 12\n",
    "    batch_idx = 0\n",
    "\n",
    "    if seed is not None:\n",
    "        L.seed_everything(seed, workers=True)\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float32):\n",
    "        batch = torch_geometric.data.Batch.from_data_list([dataset[data_idx]])\n",
    "        target, n_targets, target_ids = model.model.walker.parse_target(batch)\n",
    "        n_walks = model.model.walker.eval_n_walks\n",
    "        start_nodes, target_ids = model.model.walker.get_start_nodes(n_targets, target_ids, n_walks)\n",
    "        G = nx.to_undirected(to_networkx(batch))\n",
    "        walks, restarts = graph_walker.random_walks(\n",
    "            G=G,\n",
    "            n_walks=1,\n",
    "            walk_len=model.model.walker.walk_length,\n",
    "            min_degree=model.model.walker.min_degree,\n",
    "            sub_sampling=model.model.walker.sub_sampling,\n",
    "            p=model.model.walker.p,\n",
    "            q=model.model.walker.q,\n",
    "            alpha=model.model.walker.alpha,\n",
    "            k=model.model.walker.k,\n",
    "            no_backtrack=model.model.walker.no_backtrack,\n",
    "            start_nodes=start_nodes,\n",
    "            seed=None,\n",
    "            verbose=False\n",
    "        )\n",
    "        if model.model.walker.neighbors:\n",
    "            A = nx.adjacency_matrix(G)\n",
    "            indptr = A.indptr.astype(np.uint32)\n",
    "            indices = A.indices.astype(np.uint32)\n",
    "            named_walks, walks, restarts, neighbors = graph_walker._anonymize_with_neighbors(walks, restarts, indptr, indices)\n",
    "            text = graph_walker._as_text_with_neighbors(named_walks, restarts, neighbors)\n",
    "        else:\n",
    "            named_walks = graph_walker._anonymize(walks)\n",
    "            text = graph_walker._as_text(named_walks, restarts)\n",
    "        encoded_input = model.model.tokenizer(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=model.model.max_length\n",
    "        )\n",
    "        encoded_input = encoded_input.to(target_ids.device)\n",
    "        input_ids, attention_mask = encoded_input['input_ids'], encoded_input['attention_mask']\n",
    "        output = model.model.backbone(input_ids=input_ids, attention_mask=attention_mask, output_attentions=True)\n",
    "        pred = model.model.head(output.last_hidden_state[:, 0, :]).argmax(-1)\n",
    "\n",
    "    graph = batch[batch_idx]\n",
    "    input_text = model.model.tokenizer.batch_decode(input_ids)\n",
    "    tokenized_text = model.model.tokenizer.tokenize(input_text[batch_idx])\n",
    "    if head_idx == 'all':\n",
    "        attention = output.attentions[layer_idx][batch_idx].mean(0)\n",
    "    else:\n",
    "        attention = output.attentions[layer_idx][batch_idx][head_idx]\n",
    "    norm = plt.Normalize(0, 1.4)\n",
    "\n",
    "    colored_text = \"\"\n",
    "    attention_scores = attention[0, 1:-1] / attention[0, 1:-1].max()\n",
    "    for token, score in zip(tokenized_text[1:-1], attention_scores):\n",
    "        if token == '#':\n",
    "            token = '\\\\#'\n",
    "        val = score.item()\n",
    "        if val < 0.01:\n",
    "            r, g, b = 1, 1, 1\n",
    "        else:\n",
    "            r, g, b = matplotlib.cm.Oranges(norm(val))[:3]\n",
    "        latex_color = f\"{int(r * 255)},{int(g * 255)},{int(b * 255)}\"\n",
    "        colored_text += (f\"\\\\cctext{{{latex_color}}}{{{token}}}\")\n",
    "        if token in ('-', '\\#', ';'):\n",
    "            colored_text += \"\\\\allowbreak\"\n",
    "\n",
    "    edge_scores = torch.zeros(graph.num_edges, dtype=attention.dtype, device=attention.device)\n",
    "    edge_visited = torch.zeros(graph.num_edges, dtype=torch.bool, device=attention.device)\n",
    "    edge_times = torch.zeros(graph.num_edges, dtype=torch.int32, device=pred.device)\n",
    "\n",
    "    id2vertex = dict()\n",
    "    vertex2id = dict()\n",
    "    for id, vertex in zip(named_walks[0], walks[0]):\n",
    "        if id in id2vertex:\n",
    "            assert id2vertex[id] == vertex\n",
    "        else:\n",
    "            id2vertex[id] = vertex\n",
    "        if vertex in vertex2id:\n",
    "            assert vertex2id[vertex] == id\n",
    "        else:\n",
    "            vertex2id[vertex] = id\n",
    "\n",
    "    edge2edgeid = dict()\n",
    "    for i, (src, dst) in enumerate(graph.edge_index.unbind(1)):\n",
    "        edge2edgeid[(src.item(), dst.item())] = i\n",
    "\n",
    "    time = 0\n",
    "    for i, query_token in enumerate(tokenized_text):\n",
    "        if query_token == '[CLS]':\n",
    "            assert i == 0\n",
    "            prev = -1\n",
    "            for j, key_token in enumerate(tokenized_text):\n",
    "                if key_token in ('[CLS]', '[SEP]', '[PAD]'):\n",
    "                    continue\n",
    "                if tokenized_text[j + 1] in ('[SEP]', '[PAD]'):\n",
    "                    break\n",
    "\n",
    "                if key_token in ('-', '#', ';'):\n",
    "                    cur = int(tokenized_text[j + 1])\n",
    "                else:\n",
    "                    cur = int(key_token)\n",
    "                    if prev >= 0:\n",
    "                        if not edge_visited[edge2edgeid[(id2vertex[prev], id2vertex[cur])]].item():\n",
    "                            edge_visited[edge2edgeid[(id2vertex[prev], id2vertex[cur])]] = True\n",
    "                            edge_visited[edge2edgeid[(id2vertex[cur], id2vertex[prev])]] = True\n",
    "                            edge_times[edge2edgeid[(id2vertex[prev], id2vertex[cur])]] = time\n",
    "                            edge_times[edge2edgeid[(id2vertex[cur], id2vertex[prev])]] = time\n",
    "                        time += 1\n",
    "                if prev >= 0:\n",
    "                    edge_scores[edge2edgeid[(id2vertex[prev], id2vertex[cur])]] += attention[i, j]\n",
    "                    edge_scores[edge2edgeid[(id2vertex[cur], id2vertex[prev])]] += attention[i, j]\n",
    "\n",
    "                if key_token not in ('-', '#', ';') and (j == 1 or (tokenized_text[j - 1] == '-')):\n",
    "                    prev = cur\n",
    "\n",
    "    edge_color = (edge_scores / edge_scores.max()).cpu().detach().numpy()\n",
    "    edge_times = (edge_times.float() / edge_times.float().max()).cpu().detach().numpy()\n",
    "\n",
    "    G = nx.to_undirected(to_networkx(graph))\n",
    "    pos = nx.circular_layout(G)\n",
    "    if dataset_name == 'SR16':\n",
    "        if graph.y[batch_idx].item() == 0:\n",
    "            old2new = {0: 12, 1: 15, 2: 4, 3: 5, 4: 3, 5: 13, 6: 6, 7: 0, 8: 2, 9: 10, 10: 9, 11: 1, 12: 7, 13: 11, 14: 14, 15: 8}\n",
    "        else:\n",
    "            old2new = {0: 6, 1: 9, 2: 12, 3: 15, 4: 0, 5: 1, 6: 2, 7: 3, 8: 4, 9: 7, 10: 10, 11: 13, 12: 5, 13: 8, 14: 11, 15: 14}\n",
    "        pos = {old2new[k]: v for k, v in pos.items()}\n",
    "    for i, (src, dst, data) in enumerate(G.edges(data=True)):\n",
    "        data['weight'] = edge_color[edge2edgeid[src, dst]]\n",
    "        data['time'] = edge_times[edge2edgeid[src, dst]]\n",
    "\n",
    "    if draw_graph:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        nx.draw_networkx(G, pos, node_size=180, node_color='w', edgecolors='k', font_size=8, font_color='k', width=0.8, with_labels=False)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(root) / f'graph_{graph.y[batch_idx].item() + 1}.pdf')\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    nx.draw_networkx(G, pos, node_size=180, node_color='w', edgecolors='k', font_size=8, font_color='k', width=0.8, with_labels=False)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8, labels=vertex2id, font_color='k')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(root) / f'graph_{graph.y[batch_idx].item() + 1}_pred_{pred[batch_idx].item() + 1}_seed_{seed}.pdf')\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    edges, weights = zip(*nx.get_edge_attributes(G, 'time').items())\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=edges, edge_color=weights, width=3, edge_cmap=plt.cm.turbo)\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=180, node_color='w', edgecolors='k')\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8, labels=vertex2id, font_color='k')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(root) / f'graph_{graph.y[batch_idx].item() + 1}_pred_{pred[batch_idx].item() + 1}_time_seed_{seed}.pdf')\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    edge_list = list(G.edges(data=True))\n",
    "    edge_list.sort(key=lambda x: x[2]['weight'])\n",
    "    for edge in edge_list:\n",
    "        val = edge[2]['weight']\n",
    "        r, g, b = matplotlib.cm.Oranges(norm(val))[:3]\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=[edge], width=3, edge_color=(r, g, b), alpha=(0 if val < 0.01 else 1))\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=180, node_color='w', edgecolors='k')\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8, labels=vertex2id, font_color='k')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if head_idx == 'all':\n",
    "        plt.savefig(Path(root) / f'graph_{graph.y[batch_idx].item() + 1}_pred_{pred[batch_idx].item() + 1}_layer_{(layer_idx % num_layers) + 1}_head_all_seed_{seed}.pdf')\n",
    "        with open(Path(root) / f'graph_{graph.y[batch_idx].item() + 1}_pred_{pred[batch_idx].item() + 1}_layer_{(layer_idx % num_layers) + 1}_head_all_seed_{seed}.txt', 'w') as f:\n",
    "            f.write(colored_text)\n",
    "    else:\n",
    "        plt.savefig(Path(root) / f'graph_{graph.y[batch_idx].item() + 1}_pred_{pred[batch_idx].item() + 1}_layer_{(layer_idx % num_layers) + 1}_head_{(head_idx % num_heads) + 1}_seed_{seed}.pdf')\n",
    "        with open(Path(root) / f'graph_{graph.y[batch_idx].item() + 1}_pred_{pred[batch_idx].item() + 1}_layer_{(layer_idx % num_layers) + 1}_head_{(head_idx % num_heads) + 1}_seed_{seed}.txt', 'w') as f:\n",
    "            f.write(colored_text)\n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "    with open(Path(root) / f'graph_{graph.y[batch_idx].item() + 1}_pred_{pred[batch_idx].item() + 1}_walk_seed_{seed}.txt', 'w') as f:\n",
    "        f.write(input_text[batch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = f'experiments/figures/{dataset_name}'\n",
    "Path(root).mkdir(parents=True, exist_ok=True)\n",
    "for seed in (0, 1, 2, 42):\n",
    "    if dataset_name == 'SR16':\n",
    "        data_range = range(2)\n",
    "    elif dataset_name == 'SR25':\n",
    "        data_range = range(15)\n",
    "    elif dataset_name == 'CSL':\n",
    "        data_range = reversed(range(0, 150, 15))\n",
    "    for data_idx in data_range:\n",
    "        for layer_idx in range(12):\n",
    "            for head_idx in range(12):\n",
    "                draw(root, data_idx, layer_idx, head_idx, seed, draw_graph=(layer_idx==0 and head_idx==0))\n",
    "            draw(root, data_idx, layer_idx, 'all', seed, draw_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
